
## 离散数据的泛化模型

> 1. 贝叶斯概念学习
> 2. beta-binomial模型
> 3. Dirichlet-multinomial模型
> 4. 朴素贝叶斯分类器

### 目标

$$
p(y=c|x, \theta) ~ p(x|y=c, \theta) * p(y = c | \theta)
$$

通过离散数据推测未知参数$\theta$

### 1. 贝叶斯概念

一个数字游戏，给定一个数字集D{}属于C, C比如说是质数的合集，再给你一些新的数字，猜这些数字是否属于C

倘若不知道概念C具体是什么，通过数字集合D是否能够确定知道概念C是什么呢

比如1~100的整数，给定D{16, 8, 2, 64}能否猜测概念C是什么？当D的例子越多，是否能够更精确的猜测C?当猜测的概念C有比较多的假设情况下，比如偶数和2的平方数，当做如何选择？

做选择的话，可以用似然率(liklihood)来解释。P(D|h_2)和P(D|h_even)，根据奥卡姆剃刀原则（化繁为简）原则认为P(D|h) = (1 / size(n) )^n, n是D的个数。 P(D|h_2) = (1 / 6)^4 ~ 10^-4, P(D|h_even) = (1 / 50 )^4 ~ 10^-7，可以认定选择2的幂指数比较好

先验概率(prior)，就是对数字的假设集合，可以对假设的概率赋一个可能的值(p(h))

后验概率(posterior), p(h|D) = p(D|h) * p(h) / (sum(p(D, h'))) = ( I(D \in h) / abs(h)^N )* p(h) / sum( p(h') * ( I(D \in h') / abs(h')^N ) )

当D中的数据越来越多的时候，后验概率是几乎不受先验概率的影响。
